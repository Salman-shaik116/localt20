{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 22 4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the data using polars\n",
    "# directory = '/app/data/filteredData'\n",
    "directory = r'D:\\github\\localt20\\data\\filteredData'\n",
    "balltoball = pl.read_csv(os.path.join(directory, 'balltoball.csv'))\n",
    "teamStats = pl.read_csv(os.path.join(directory, 'team12Stats.csv'))\n",
    "playersStats = pl.read_csv(os.path.join(directory, 'playersStats.csv'))\n",
    "\n",
    "# Preprocess the data\n",
    "def partition_data(df, group_keys):\n",
    "    partitions = df.partition_by(group_keys)\n",
    "    partition_list = [partition.drop(group_keys).to_numpy() for partition in partitions]\n",
    "    return partition_list\n",
    "\n",
    "team_stats_partitions = partition_data(teamStats, ['match_id', 'flip'])\n",
    "player_stats_partitions = partition_data(playersStats, ['match_id', 'flip'])\n",
    "ball_stats_partitions = partition_data(balltoball, ['match_id', 'flip'])\n",
    "\n",
    "# Create a custom Dataset\n",
    "class CricketDataset(Dataset):\n",
    "    def __init__(self, team_stats_list, player_stats_list, ball_stats_list):\n",
    "        self.team_stats_list = team_stats_list\n",
    "        self.player_stats_list = player_stats_list\n",
    "        self.ball_stats_list = ball_stats_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.team_stats_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        team_input = torch.tensor(self.team_stats_list[idx], dtype=torch.float32)\n",
    "        player_input = torch.tensor(self.player_stats_list[idx], dtype=torch.float32)\n",
    "        ball_stats = torch.tensor(self.ball_stats_list[idx], dtype=torch.float32)\n",
    "        # Assuming the last column is the label\n",
    "        ball_input = ball_stats[:, :-1]\n",
    "        label = ball_stats[0, -1]\n",
    "        return team_input, player_input, ball_input, label\n",
    "\n",
    "# Define a collate function to handle variable-length sequences\n",
    "def collate_fn(batch):\n",
    "    team_inputs = []\n",
    "    player_inputs = []\n",
    "    ball_inputs = []\n",
    "    labels = []\n",
    "    ball_lengths = []\n",
    "\n",
    "    for team_input, player_input, ball_input, label in batch:\n",
    "        team_inputs.append(team_input)\n",
    "        player_inputs.append(player_input)\n",
    "        ball_inputs.append(ball_input)\n",
    "        labels.append(label)\n",
    "        ball_lengths.append(ball_input.shape[0])\n",
    "\n",
    "    # Pad ball_inputs to the maximum sequence length in the batch\n",
    "    max_seq_len = max(ball_lengths)\n",
    "    padded_ball_inputs = torch.zeros(len(ball_inputs), max_seq_len, ball_inputs[0].shape[1])\n",
    "    for i, ball_input in enumerate(ball_inputs):\n",
    "        seq_len = ball_input.shape[0]\n",
    "        padded_ball_inputs[i, :seq_len, :] = ball_input\n",
    "\n",
    "    team_inputs = torch.stack(team_inputs)\n",
    "    player_inputs = torch.stack(player_inputs)\n",
    "    labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    return team_inputs, player_inputs, padded_ball_inputs, labels, ball_lengths\n",
    "\n",
    "# Create the Dataset and DataLoader with data augmentation\n",
    "def augment_data(team_input, player_input, ball_input):\n",
    "    # Implement data augmentation strategies if needed\n",
    "    # For example, adding noise or random transformations\n",
    "    return team_input, player_input, ball_input\n",
    "\n",
    "dataset = CricketDataset(team_stats_partitions, player_stats_partitions, ball_stats_partitions)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# Define the models\n",
    "class TeamStatsModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(TeamStatsModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class PlayerStatsModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(PlayerStatsModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=32, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(64 * ((input_size - 4) // 4), 16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # Convert to (batch, channels, seq_len)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc(x))\n",
    "        return x\n",
    "\n",
    "class BallToBallModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(BallToBallModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, 128, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(256, 16)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # Pack the sequences\n",
    "        x_packed = nn.utils.rnn.pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        output_packed, (hn, cn) = self.lstm(x_packed)\n",
    "        # Concatenate the final forward and backward hidden states\n",
    "        hn = torch.cat((hn[-2,:,:], hn[-1,:,:]), dim=1)\n",
    "        x = self.dropout(hn)\n",
    "        x = F.relu(self.fc(x))\n",
    "        return x\n",
    "\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, team_input_size, player_input_size, ball_input_dim):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.team_model = TeamStatsModel(team_input_size)\n",
    "        self.player_model = PlayerStatsModel(player_input_size)\n",
    "        self.ball_model = BallToBallModel(ball_input_dim)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16+16+16, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, team_input, player_input, ball_input, ball_lengths):\n",
    "        team_output = self.team_model(team_input)\n",
    "        player_output = self.player_model(player_input)\n",
    "        ball_output = self.ball_model(ball_input, ball_lengths)\n",
    "        combined = torch.cat((team_output, player_output, ball_output), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output.squeeze()\n",
    "\n",
    "# Initialize the model\n",
    "team_input_size = team_stats_partitions[0].shape[1]\n",
    "player_input_size = player_stats_partitions[0].shape[1]\n",
    "ball_input_dim = ball_stats_partitions[0].shape[1] - 1  # Exclude label\n",
    "\n",
    "print(team_input_size, player_input_size, ball_input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CombinedModel(team_input_size, player_input_size, ball_input_dim)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)  # Weight decay for regularization\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Implement early stopping\n",
    "best_loss = np.inf\n",
    "patience = 10\n",
    "trigger_times = 0\n",
    "\n",
    "# Training loop with tqdm\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for team_input, player_input, ball_input, labels, ball_lengths in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(team_input, player_input, ball_input, ball_lengths)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Early stopping logic\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        trigger_times = 0\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        if trigger_times >= patience:\n",
    "            print('Early stopping!')\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
