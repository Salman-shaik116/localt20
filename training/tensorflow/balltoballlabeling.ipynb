{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team Stats Sample Shape: (1, 23)\n",
      "Players Stats Sample Shape: (22, 22)\n",
      "Ball to Ball Stats Sample Shape: (215, None)\n",
      "Ball to Ball Stats Sample Value: tf.Tensor([1.  0.1 0.  0.  1. ], shape=(5,), dtype=float64)\n",
      "Team Stats Sample Shape: (1, 23)\n",
      "Players Stats Sample Shape: (22, 22)\n",
      "Ball to Ball Stats Sample Shape: (215, None)\n",
      "Sample 0: (<tf.Tensor: shape=(1, 23), dtype=float64, numpy=\n",
      "array([[  1.  ,   1.  ,   1.  ,   0.  ,   0.  ,   0.  ,   1.  ,   1.  ,\n",
      "        179.  ,   0.  ,  22.37,   8.95,   1.  ,   0.  ,   1.  ,   0.  ,\n",
      "          0.  ,   0.  ,   1.  ,  79.  ,  79.  ,   7.9 ,   5.44]])>, <tf.Tensor: shape=(22, 22), dtype=float64, numpy=\n",
      "array([[  1.  ,   1.  ,  15.  , 107.14,  15.  ,   8.  ,  16.  ,   2.  ,\n",
      "         70.24,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ],\n",
      "       [  1.  ,   1.  ,   6.  , 150.  ,   6.  ,   6.  ,   6.  ,   1.  ,\n",
      "        150.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   0.  ,   1.  ,   1.  ,   0.  ,   1.  ],\n",
      "       [  1.  ,   1.  ,   0.  ,   0.  ,   0.  ,  16.  ,  32.  ,   2.  ,\n",
      "        123.08,   3.  ,  14.  ,   2.  ,   4.66,   6.  ,   3.  ,  47.  ,\n",
      "          2.  ,  23.5 ,   1.  ,   1.  ,   0.  ,   0.5 ],\n",
      "       [  1.  ,   1.  ,   0.  ,   0.  ,   0.  ,   3.5 ,   7.  ,   2.  ,\n",
      "         87.5 ,   3.  ,  25.  ,   1.  ,   8.33,   5.  ,   1.  ,  36.  ,\n",
      "          2.  ,  18.  ,   0.  ,   0.  ,   0.  ,   0.  ],\n",
      "       [  1.  ,   1.  ,   1.  ,  16.66,   1.  ,  16.  ,  32.  ,   2.  ,\n",
      "        111.66,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   0.  ,   3.  ,   3.  ,   0.  ,   1.5 ],\n",
      "       [  1.  ,   1.  ,   0.  ,   0.  ,   0.  ,  49.  ,  98.  ,   2.  ,\n",
      "         89.09,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   0.  ,   3.  ,   3.  ,   0.  ,   1.5 ],\n",
      "       [  1.  ,   1.  ,   4.  , 100.  ,   4.  ,   3.5 ,   7.  ,   2.  ,\n",
      "         80.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ],\n",
      "       [  1.  ,   1.  ,  15.  ,  75.  ,  15.  ,  15.  ,  15.  ,   1.  ,\n",
      "         37.5 ,   3.  ,  31.  ,   0.  ,  10.33,   7.  ,   1.  ,  57.  ,\n",
      "          2.  ,  28.5 ,   0.  ,   0.  ,   0.  ,   0.  ],\n",
      "       [  1.  ,   1.  ,  24.  , 133.33,  24.  ,  24.  ,  24.  ,   1.  ,\n",
      "        133.33,   4.  ,  49.  ,   1.  ,  12.25,   4.  ,   1.  ,  49.  ,\n",
      "          1.  ,  49.  ,   0.  ,   0.  ,   0.  ,   0.  ],\n",
      "       [  1.  ,   1.  ,   3.  ,  60.  ,   3.  ,   3.  ,   3.  ,   1.  ,\n",
      "         30.  ,   3.  ,  28.  ,   1.  ,   9.33,   7.  ,   5.  ,  57.  ,\n",
      "          2.  ,  28.5 ,   2.  ,   2.  ,   0.  ,   1.  ],\n",
      "       [  1.  ,   1.  ,   5.  ,  41.66,   5.  ,   5.  ,   5.  ,   1.  ,\n",
      "         20.83,   4.  ,  31.  ,   3.  ,   7.75,   8.  ,   5.  ,  79.  ,\n",
      "          2.  ,  39.5 ,   1.  ,   1.  ,   0.  ,   0.5 ],\n",
      "       [  1.  ,   1.  ,  41.  , 110.81,  41.  ,  41.  ,  41.  ,   1.  ,\n",
      "        110.81,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   0.  ,   2.  ,   2.  ,   0.  ,   2.  ],\n",
      "       [  1.  ,   1.  ,  19.  , 135.71,  19.  ,  19.  ,  19.  ,   1.  ,\n",
      "        135.71,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   0.  ,   1.  ,   1.  ,   0.  ,   1.  ],\n",
      "       [  1.  ,   1.  ,   6.  , 120.  ,   6.  ,   6.  ,   6.  ,   1.  ,\n",
      "        120.  ,   3.  ,  15.  ,   0.  ,   5.  ,   3.  ,   0.  ,  15.  ,\n",
      "          1.  ,  15.  ,   1.  ,   1.  ,   0.  ,   1.  ],\n",
      "       [  1.  ,   1.  ,  34.  , 188.88,  34.  ,  34.  ,  34.  ,   1.  ,\n",
      "        188.88,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   0.  ,   3.  ,   3.  ,   0.  ,   3.  ],\n",
      "       [  1.  ,   1.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   1.  ,\n",
      "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ],\n",
      "       [  1.  ,   1.  ,  46.  , 176.92,  46.  ,  46.  ,  46.  ,   1.  ,\n",
      "        176.92,   2.  ,   8.  ,   2.  ,   4.  ,   2.  ,   2.  ,   8.  ,\n",
      "          1.  ,   8.  ,   0.  ,   0.  ,   0.  ,   0.  ],\n",
      "       [  1.  ,   1.  ,  18.  , 112.5 ,  18.  ,  18.  ,  18.  ,   1.  ,\n",
      "        112.5 ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ],\n",
      "       [  1.  ,   1.  ,   9.  , 180.  ,   9.  ,   9.  ,   9.  ,   1.  ,\n",
      "        180.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   0.  ,   1.  ,   1.  ,   0.  ,   1.  ],\n",
      "       [  1.  ,   1.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   1.  ,\n",
      "          0.  ,   4.  ,  24.  ,   4.  ,   6.  ,   4.  ,   4.  ,  24.  ,\n",
      "          1.  ,  24.  ,   0.  ,   0.  ,   0.  ,   0.  ],\n",
      "       [  1.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   3.  ,  16.  ,   3.  ,   5.33,   3.  ,   3.  ,  16.  ,\n",
      "          1.  ,  16.  ,   0.  ,   0.  ,   0.  ,   0.  ],\n",
      "       [  1.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   2.3 ,  13.  ,   1.  ,   5.2 ,   2.3 ,   1.  ,  13.  ,\n",
      "          1.  ,  13.  ,   1.  ,   1.  ,   0.  ,   1.  ]])>, <tf.RaggedTensor [[1.0, 0.1, 0.0, 0.0, 1.0],\n",
      " [1.0, 0.2, 1.0, 0.0, 1.0],\n",
      " [1.0, 0.3, 1.0, 0.0, 1.0],\n",
      " ...,\n",
      " [2.0, 14.1, 85.0, 9.0, 1.0],\n",
      " [2.0, 14.2, 85.0, 9.0, 1.0],\n",
      " [2.0, 14.3, 85.0, 10.0, 1.0]]>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 04:49:52.551909: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team Stats Sample Shape: (1, 23)\n",
      "Players Stats Sample Shape: (22, 22)\n",
      "Ball to Ball Stats Sample Shape: (215, None)\n",
      "Ball to Ball Stats Sample Value: tf.Tensor([1.  0.1 0.  0.  1. ], shape=(5,), dtype=float64)\n",
      "Team Stats Sample Shape: (1, 23)\n",
      "Players Stats Sample Shape: (22, 22)\n",
      "Ball to Ball Stats Sample Shape: (215, None)\n",
      "Sample 0: (<tf.Tensor: shape=(1, 23), dtype=float64, numpy=\n",
      "array([[  1.  ,   1.  ,   1.  ,   0.  ,   0.  ,   0.  ,   1.  ,   1.  ,\n",
      "        179.  ,   0.  ,  22.37,   8.95,   1.  ,   0.  ,   1.  ,   0.  ,\n",
      "          0.  ,   0.  ,   1.  ,  79.  ,  79.  ,   7.9 ,   5.44]])>, <tf.Tensor: shape=(22, 22), dtype=float64, numpy=\n",
      "array([[  1.  ,   1.  ,  15.  , 107.14,  15.  ,   8.  ,  16.  ,   2.  ,\n",
      "         70.24,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ],\n",
      "       [  1.  ,   1.  ,   6.  , 150.  ,   6.  ,   6.  ,   6.  ,   1.  ,\n",
      "        150.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   0.  ,   1.  ,   1.  ,   0.  ,   1.  ],\n",
      "       [  1.  ,   1.  ,   0.  ,   0.  ,   0.  ,  16.  ,  32.  ,   2.  ,\n",
      "        123.08,   3.  ,  14.  ,   2.  ,   4.66,   6.  ,   3.  ,  47.  ,\n",
      "          2.  ,  23.5 ,   1.  ,   1.  ,   0.  ,   0.5 ],\n",
      "       [  1.  ,   1.  ,   0.  ,   0.  ,   0.  ,   3.5 ,   7.  ,   2.  ,\n",
      "         87.5 ,   3.  ,  25.  ,   1.  ,   8.33,   5.  ,   1.  ,  36.  ,\n",
      "          2.  ,  18.  ,   0.  ,   0.  ,   0.  ,   0.  ],\n",
      "       [  1.  ,   1.  ,   1.  ,  16.66,   1.  ,  16.  ,  32.  ,   2.  ,\n",
      "        111.66,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   0.  ,   3.  ,   3.  ,   0.  ,   1.5 ],\n",
      "       [  1.  ,   1.  ,   0.  ,   0.  ,   0.  ,  49.  ,  98.  ,   2.  ,\n",
      "         89.09,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   0.  ,   3.  ,   3.  ,   0.  ,   1.5 ],\n",
      "       [  1.  ,   1.  ,   4.  , 100.  ,   4.  ,   3.5 ,   7.  ,   2.  ,\n",
      "         80.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ],\n",
      "       [  1.  ,   1.  ,  15.  ,  75.  ,  15.  ,  15.  ,  15.  ,   1.  ,\n",
      "         37.5 ,   3.  ,  31.  ,   0.  ,  10.33,   7.  ,   1.  ,  57.  ,\n",
      "          2.  ,  28.5 ,   0.  ,   0.  ,   0.  ,   0.  ],\n",
      "       [  1.  ,   1.  ,  24.  , 133.33,  24.  ,  24.  ,  24.  ,   1.  ,\n",
      "        133.33,   4.  ,  49.  ,   1.  ,  12.25,   4.  ,   1.  ,  49.  ,\n",
      "          1.  ,  49.  ,   0.  ,   0.  ,   0.  ,   0.  ],\n",
      "       [  1.  ,   1.  ,   3.  ,  60.  ,   3.  ,   3.  ,   3.  ,   1.  ,\n",
      "         30.  ,   3.  ,  28.  ,   1.  ,   9.33,   7.  ,   5.  ,  57.  ,\n",
      "          2.  ,  28.5 ,   2.  ,   2.  ,   0.  ,   1.  ],\n",
      "       [  1.  ,   1.  ,   5.  ,  41.66,   5.  ,   5.  ,   5.  ,   1.  ,\n",
      "         20.83,   4.  ,  31.  ,   3.  ,   7.75,   8.  ,   5.  ,  79.  ,\n",
      "          2.  ,  39.5 ,   1.  ,   1.  ,   0.  ,   0.5 ],\n",
      "       [  1.  ,   1.  ,  41.  , 110.81,  41.  ,  41.  ,  41.  ,   1.  ,\n",
      "        110.81,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   0.  ,   2.  ,   2.  ,   0.  ,   2.  ],\n",
      "       [  1.  ,   1.  ,  19.  , 135.71,  19.  ,  19.  ,  19.  ,   1.  ,\n",
      "        135.71,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   0.  ,   1.  ,   1.  ,   0.  ,   1.  ],\n",
      "       [  1.  ,   1.  ,   6.  , 120.  ,   6.  ,   6.  ,   6.  ,   1.  ,\n",
      "        120.  ,   3.  ,  15.  ,   0.  ,   5.  ,   3.  ,   0.  ,  15.  ,\n",
      "          1.  ,  15.  ,   1.  ,   1.  ,   0.  ,   1.  ],\n",
      "       [  1.  ,   1.  ,  34.  , 188.88,  34.  ,  34.  ,  34.  ,   1.  ,\n",
      "        188.88,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   0.  ,   3.  ,   3.  ,   0.  ,   3.  ],\n",
      "       [  1.  ,   1.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   1.  ,\n",
      "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ],\n",
      "       [  1.  ,   1.  ,  46.  , 176.92,  46.  ,  46.  ,  46.  ,   1.  ,\n",
      "        176.92,   2.  ,   8.  ,   2.  ,   4.  ,   2.  ,   2.  ,   8.  ,\n",
      "          1.  ,   8.  ,   0.  ,   0.  ,   0.  ,   0.  ],\n",
      "       [  1.  ,   1.  ,  18.  , 112.5 ,  18.  ,  18.  ,  18.  ,   1.  ,\n",
      "        112.5 ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ],\n",
      "       [  1.  ,   1.  ,   9.  , 180.  ,   9.  ,   9.  ,   9.  ,   1.  ,\n",
      "        180.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   0.  ,   1.  ,   1.  ,   0.  ,   1.  ],\n",
      "       [  1.  ,   1.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   1.  ,\n",
      "          0.  ,   4.  ,  24.  ,   4.  ,   6.  ,   4.  ,   4.  ,  24.  ,\n",
      "          1.  ,  24.  ,   0.  ,   0.  ,   0.  ,   0.  ],\n",
      "       [  1.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   3.  ,  16.  ,   3.  ,   5.33,   3.  ,   3.  ,  16.  ,\n",
      "          1.  ,  16.  ,   0.  ,   0.  ,   0.  ,   0.  ],\n",
      "       [  1.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
      "          0.  ,   2.3 ,  13.  ,   1.  ,   5.2 ,   2.3 ,   1.  ,  13.  ,\n",
      "          1.  ,  13.  ,   1.  ,   1.  ,   0.  ,   1.  ]])>, <tf.RaggedTensor [[1.0, 0.1, 0.0, 0.0, 1.0],\n",
      " [1.0, 0.2, 1.0, 0.0, 1.0],\n",
      " [1.0, 0.3, 1.0, 0.0, 1.0],\n",
      " ...,\n",
      " [2.0, 14.1, 85.0, 9.0, 1.0],\n",
      " [2.0, 14.2, 85.0, 9.0, 1.0],\n",
      " [2.0, 14.3, 85.0, 10.0, 1.0]]>)\n",
      "(1, 23) (22, 22) (2312, 271, 4) (2312,)\n",
      "Shape of team_input: (2312, 1, 23)\n",
      "Shape of player_input: (2312, 22, 22)\n",
      "Shape of ball_input: (2312, 271, 4)\n",
      "Shape of labels: (2312,)\n",
      "Epoch 1/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 304ms/step - accuracy: 0.5365 - loss: 22.7232 - val_accuracy: 0.5054 - val_loss: 8.4277 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - accuracy: 0.5243 - loss: 6.4868 - val_accuracy: 0.5508 - val_loss: 6.1739 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - accuracy: 0.6027 - loss: 4.6222 - val_accuracy: 0.5572 - val_loss: 5.1403 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.6048 - loss: 3.9453 - val_accuracy: 0.5486 - val_loss: 4.5403 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - accuracy: 0.6344 - loss: 3.1131 - val_accuracy: 0.5918 - val_loss: 3.8465 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.6407 - loss: 2.7298 - val_accuracy: 0.5680 - val_loss: 3.9773 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.6573 - loss: 2.1217 - val_accuracy: 0.5680 - val_loss: 3.5170 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.6666 - loss: 1.8573 - val_accuracy: 0.5551 - val_loss: 3.0693 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.6817 - loss: 1.7296 - val_accuracy: 0.5918 - val_loss: 3.1908 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.6789 - loss: 1.6605 - val_accuracy: 0.5896 - val_loss: 2.8711 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.7001 - loss: 1.4057 - val_accuracy: 0.5983 - val_loss: 2.8558 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.7106 - loss: 1.2270 - val_accuracy: 0.6220 - val_loss: 2.9338 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.7413 - loss: 1.0726 - val_accuracy: 0.6069 - val_loss: 2.7326 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.7220 - loss: 1.1102 - val_accuracy: 0.6069 - val_loss: 2.5340 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.7322 - loss: 1.0057 - val_accuracy: 0.6134 - val_loss: 2.4453 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.7609 - loss: 0.8021 - val_accuracy: 0.6048 - val_loss: 2.2507 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.7722 - loss: 0.7627 - val_accuracy: 0.6263 - val_loss: 2.3635 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.7765 - loss: 0.7383 - val_accuracy: 0.6026 - val_loss: 2.4591 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.7790 - loss: 0.6784 - val_accuracy: 0.5940 - val_loss: 2.3224 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.7760 - loss: 0.7049 - val_accuracy: 0.6048 - val_loss: 2.2734 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.7918 - loss: 0.5977 - val_accuracy: 0.6199 - val_loss: 2.3034 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.8182 - loss: 0.5564 - val_accuracy: 0.6177 - val_loss: 2.2638 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.8193 - loss: 0.4769 - val_accuracy: 0.6069 - val_loss: 2.2173 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.8486 - loss: 0.4151 - val_accuracy: 0.6134 - val_loss: 2.2417 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.8226 - loss: 0.4662 - val_accuracy: 0.6156 - val_loss: 2.2588 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.8437 - loss: 0.4539 - val_accuracy: 0.6199 - val_loss: 2.2443 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.8482 - loss: 0.4463 - val_accuracy: 0.6134 - val_loss: 2.2067 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.8754 - loss: 0.3613 - val_accuracy: 0.6091 - val_loss: 2.2124 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.8513 - loss: 0.4429 - val_accuracy: 0.6112 - val_loss: 2.2279 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.8579 - loss: 0.3956 - val_accuracy: 0.6156 - val_loss: 2.1646 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.8626 - loss: 0.3461 - val_accuracy: 0.6177 - val_loss: 2.2272 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 108ms/step - accuracy: 0.8684 - loss: 0.3296 - val_accuracy: 0.6285 - val_loss: 2.3107 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.8518 - loss: 0.3908 - val_accuracy: 0.6069 - val_loss: 2.2351 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.8839 - loss: 0.3249 - val_accuracy: 0.6134 - val_loss: 2.2203 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.8972 - loss: 0.2810 - val_accuracy: 0.6026 - val_loss: 2.1966 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.8981 - loss: 0.2712 - val_accuracy: 0.6026 - val_loss: 2.1785 - learning_rate: 2.5000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.8929 - loss: 0.3020 - val_accuracy: 0.6048 - val_loss: 2.1993 - learning_rate: 2.5000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.8840 - loss: 0.3236 - val_accuracy: 0.6112 - val_loss: 2.1411 - learning_rate: 2.5000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9133 - loss: 0.2560 - val_accuracy: 0.6177 - val_loss: 2.2002 - learning_rate: 2.5000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9014 - loss: 0.2668 - val_accuracy: 0.6004 - val_loss: 2.1944 - learning_rate: 2.5000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9180 - loss: 0.2549 - val_accuracy: 0.6048 - val_loss: 2.1877 - learning_rate: 2.5000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9078 - loss: 0.2551 - val_accuracy: 0.6069 - val_loss: 2.1493 - learning_rate: 2.5000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.9127 - loss: 0.2761 - val_accuracy: 0.6134 - val_loss: 2.1971 - learning_rate: 2.5000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.9048 - loss: 0.2724 - val_accuracy: 0.6026 - val_loss: 2.1696 - learning_rate: 1.2500e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9115 - loss: 0.2731 - val_accuracy: 0.6069 - val_loss: 2.1589 - learning_rate: 1.2500e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9121 - loss: 0.2350 - val_accuracy: 0.6069 - val_loss: 2.1730 - learning_rate: 1.2500e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9261 - loss: 0.2213 - val_accuracy: 0.6026 - val_loss: 2.1767 - learning_rate: 1.2500e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.9177 - loss: 0.2427 - val_accuracy: 0.6048 - val_loss: 2.1692 - learning_rate: 1.2500e-05\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.6256 - loss: 2.1668\n",
      "Validation Loss: 2.1408960819244385, Validation Accuracy: 0.6112310886383057\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    for gpu in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(gpu,True)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "\n",
    "# Load the data (assuming your data files are in the correct directory as specified)\n",
    "directory = '/app/data/filteredData'\n",
    "balltoball = pl.read_csv(os.path.join(directory, 'balltoball.csv'))\n",
    "teamStats = pl.read_csv(os.path.join(directory, 'team12Stats.csv'))\n",
    "playersStats = pl.read_csv(os.path.join(directory, 'playersStats.csv'))\n",
    "\n",
    "\n",
    "partitions = teamStats.partition_by(['match_id', 'flip'])\n",
    "partitions = np.array([partition.drop(['match_id','flip']).to_numpy() for partition in partitions])\n",
    "tstf = tf.data.Dataset.from_tensor_slices(partitions)\n",
    "partitions = playersStats.partition_by(['match_id', 'flip'])\n",
    "partitions = np.array([partition.drop(['match_id','flip']).to_numpy() for partition in partitions])\n",
    "pstf = tf.data.Dataset.from_tensor_slices(partitions)\n",
    "partitions = balltoball.partition_by(['match_id', 'flip'])\n",
    "# Create a ragged tensor from a list of tensors\n",
    "ragged_tensor = tf.ragged.constant([partition.drop(['match_id','flip']).to_numpy() for partition in partitions])\n",
    "bbtf = tf.data.Dataset.from_tensor_slices(ragged_tensor)\n",
    "\n",
    "\n",
    "# Print the shapes of the datasets\n",
    "for sample in tstf.take(1):\n",
    "    print(\"Team Stats Sample Shape:\", sample.shape)\n",
    "\n",
    "for sample in pstf.take(1):\n",
    "    print(\"Players Stats Sample Shape:\", sample.shape)\n",
    "\n",
    "for sample in bbtf.take(1):\n",
    "    print(\"Ball to Ball Stats Sample Shape:\", sample.shape)\n",
    "    print(\"Ball to Ball Stats Sample Value:\", sample[0])\n",
    "\n",
    "combined_dataset = tf.data.Dataset.zip((tstf, pstf, bbtf))\n",
    "for sample in combined_dataset.take(1):\n",
    "    print(\"Team Stats Sample Shape:\", sample[0].shape)\n",
    "    print(\"Players Stats Sample Shape:\", sample[1].shape)\n",
    "    print(\"Ball to Ball Stats Sample Shape:\", sample[2].shape)\n",
    "    print(\"Sample 0:\", sample)\n",
    "\n",
    "\n",
    "# Assuming `combined_dataset` is your tf.data.Dataset containing the ball stats and labels\n",
    "def extract_labels_and_data(combined_dataset):\n",
    "    data_samples = []\n",
    "    labels = []\n",
    "    for sample in combined_dataset:\n",
    "        # Convert ragged tensor to uniform tensor\n",
    "        ball_stats = sample[2].to_tensor()\n",
    "        # Extract ball stats and labels\n",
    "        data_sample = ball_stats[:, :-1]  # Assuming last column is the label\n",
    "        label = ball_stats[:, -1]  # Last column as labels\n",
    "        data_samples.append(data_sample)\n",
    "        labels.append(label)\n",
    "    return data_samples, labels\n",
    "\n",
    "ball_data_samples, labels = extract_labels_and_data(combined_dataset)\n",
    "# Prepare the data for training\n",
    "def prepare_dataset(combined_dataset):\n",
    "    team_stats_data = []\n",
    "    player_stats_data = []\n",
    "    ball_stats_data = []\n",
    "    labels = []\n",
    "    for sample in combined_dataset:\n",
    "        team_stats_sample = sample[0]\n",
    "        player_stats_sample = sample[1]\n",
    "        ball_stats_sample = sample[2].to_tensor()\n",
    "\n",
    "        # Assuming last column is the label\n",
    "        data_sample = ball_stats_sample[:, :-1]\n",
    "        label = ball_stats_sample[0, -1]  # Assuming label is the same across the sequence\n",
    "\n",
    "        team_stats_data.append(team_stats_sample)\n",
    "        player_stats_data.append(player_stats_sample)\n",
    "        ball_stats_data.append(data_sample)\n",
    "        labels.append(label)\n",
    "\n",
    "    # Pad ball_stats_data sequences to the same length\n",
    "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "    ball_stats_data = pad_sequences([data.numpy() for data in ball_stats_data], padding='post', dtype='float32')\n",
    "\n",
    "    return (tf.stack(team_stats_data), tf.stack(player_stats_data), tf.convert_to_tensor(ball_stats_data)), tf.convert_to_tensor(labels)\n",
    "\n",
    "# Prepare the dataset\n",
    "inputs, labels = prepare_dataset(combined_dataset)\n",
    "\n",
    "# save the prepared data\n",
    "tf.data.experimental.save(inputs, '/app/data/reshaped/inputs')\n",
    "\n",
    "# Adjust input shapes based on prepared data\n",
    "team_input_shape = inputs[0].shape[1:]\n",
    "player_input_shape = inputs[1].shape[1:]\n",
    "team_input_shape, player_input_shape, inputs[2].shape, labels.shape\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    for gpu in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(gpu,True)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "\n",
    "# Load the data (assuming your data files are in the correct directory as specified)\n",
    "directory = '/app/data/filteredData'\n",
    "balltoball = pl.read_csv(os.path.join(directory, 'balltoball.csv'))\n",
    "teamStats = pl.read_csv(os.path.join(directory, 'team12Stats.csv'))\n",
    "playersStats = pl.read_csv(os.path.join(directory, 'playersStats.csv'))\n",
    "\n",
    "\n",
    "partitions = teamStats.partition_by(['match_id', 'flip'])\n",
    "partitions = np.array([partition.drop(['match_id','flip']).to_numpy() for partition in partitions])\n",
    "tstf = tf.data.Dataset.from_tensor_slices(partitions)\n",
    "partitions = playersStats.partition_by(['match_id', 'flip'])\n",
    "partitions = np.array([partition.drop(['match_id','flip']).to_numpy() for partition in partitions])\n",
    "pstf = tf.data.Dataset.from_tensor_slices(partitions)\n",
    "partitions = balltoball.partition_by(['match_id', 'flip'])\n",
    "# Create a ragged tensor from a list of tensors\n",
    "ragged_tensor = tf.ragged.constant([partition.drop(['match_id','flip']).to_numpy() for partition in partitions])\n",
    "bbtf = tf.data.Dataset.from_tensor_slices(ragged_tensor)\n",
    "\n",
    "\n",
    "# Print the shapes of the datasets\n",
    "for sample in tstf.take(1):\n",
    "    print(\"Team Stats Sample Shape:\", sample.shape)\n",
    "\n",
    "for sample in pstf.take(1):\n",
    "    print(\"Players Stats Sample Shape:\", sample.shape)\n",
    "\n",
    "for sample in bbtf.take(1):\n",
    "    print(\"Ball to Ball Stats Sample Shape:\", sample.shape)\n",
    "    print(\"Ball to Ball Stats Sample Value:\", sample[0])\n",
    "\n",
    "combined_dataset = tf.data.Dataset.zip((tstf, pstf, bbtf))\n",
    "for sample in combined_dataset.take(1):\n",
    "    print(\"Team Stats Sample Shape:\", sample[0].shape)\n",
    "    print(\"Players Stats Sample Shape:\", sample[1].shape)\n",
    "    print(\"Ball to Ball Stats Sample Shape:\", sample[2].shape)\n",
    "    print(\"Sample 0:\", sample)\n",
    "\n",
    "# Assuming `combined_dataset` is your tf.data.Dataset containing the ball stats and labels\n",
    "def extract_labels_and_data(combined_dataset):\n",
    "    data_samples = []\n",
    "    labels = []\n",
    "    for sample in combined_dataset:\n",
    "        # Convert ragged tensor to uniform tensor\n",
    "        ball_stats = sample[2].to_tensor()\n",
    "        # Extract ball stats and labels\n",
    "        data_sample = ball_stats[:, :-1]  # Assuming last column is the label\n",
    "        label = ball_stats[:, -1]  # Last column as labels\n",
    "        data_samples.append(data_sample)\n",
    "        labels.append(label)\n",
    "    return data_samples, labels\n",
    "\n",
    "ball_data_samples, labels = extract_labels_and_data(combined_dataset)\n",
    "# Prepare the data for training\n",
    "def prepare_dataset(combined_dataset):\n",
    "    team_stats_data = []\n",
    "    player_stats_data = []\n",
    "    ball_stats_data = []\n",
    "    labels = []\n",
    "    for sample in combined_dataset:\n",
    "        team_stats_sample = sample[0]\n",
    "        player_stats_sample = sample[1]\n",
    "        ball_stats_sample = sample[2].to_tensor()\n",
    "\n",
    "        # Assuming last column is the label\n",
    "        data_sample = ball_stats_sample[:, :-1]\n",
    "        label = ball_stats_sample[0, -1]  # Assuming label is the same across the sequence\n",
    "\n",
    "        team_stats_data.append(team_stats_sample)\n",
    "        player_stats_data.append(player_stats_sample)\n",
    "        ball_stats_data.append(data_sample)\n",
    "        labels.append(label)\n",
    "\n",
    "    # Pad ball_stats_data sequences to the same length\n",
    "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "    ball_stats_data = pad_sequences([data.numpy() for data in ball_stats_data], padding='post', dtype='float32')\n",
    "\n",
    "    return (tf.stack(team_stats_data), tf.stack(player_stats_data), tf.convert_to_tensor(ball_stats_data)), tf.convert_to_tensor(labels)\n",
    "\n",
    "# Prepare the dataset\n",
    "inputs, labels = prepare_dataset(combined_dataset)\n",
    "\n",
    "# Adjust input shapes based on prepared data\n",
    "team_input_shape = inputs[0].shape[1:]\n",
    "player_input_shape = inputs[1].shape[1:]\n",
    "print(team_input_shape, player_input_shape, inputs[2].shape, labels.shape)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras import layers\n",
    "# Define the Team Stats Model (DNN)\n",
    "class TeamStatsModel(tf.keras.Model):\n",
    "    def __init__(self, input_shape):\n",
    "        super(TeamStatsModel, self).__init__()\n",
    "        self.dense1 = layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.dropout1 = layers.Dropout(0.3)\n",
    "        \n",
    "        self.dense2 = layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.dropout2 = layers.Dropout(0.3)\n",
    "        \n",
    "        self.output_layer = layers.Dense(16, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.dense2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Define the Player Stats Model (CNN)\n",
    "class PlayerStatsModel(tf.keras.Model):\n",
    "    def __init__(self, input_shape):\n",
    "        super(PlayerStatsModel, self).__init__()\n",
    "        self.conv1 = layers.Conv1D(32, kernel_size=3, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.pool1 = layers.MaxPooling1D(pool_size=2)\n",
    "\n",
    "        self.conv2 = layers.Conv1D(64, kernel_size=3, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.pool2 = layers.MaxPooling1D(pool_size=2)\n",
    "\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.output_layer = layers.Dense(16, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)  # Fixed from inputs to x\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Update the BallToBallModel\n",
    "class BallToBallModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(BallToBallModel, self).__init__()\n",
    "        # Add a projection layer to match the input dimension to the model dimension\n",
    "        self.projection = layers.Dense(128)\n",
    "        self.layer_norm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.attention1 = layers.MultiHeadAttention(num_heads=8, key_dim=128)\n",
    "        self.dropout1 = layers.Dropout(0.3)\n",
    "        self.ffn1 = tf.keras.Sequential([\n",
    "            layers.Dense(128, activation='relu', kernel_initializer=\"he_normal\"),\n",
    "            layers.Dense(128, activation='relu', kernel_initializer=\"he_normal\"),\n",
    "        ])\n",
    "\n",
    "        self.layer_norm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.attention2 = layers.MultiHeadAttention(num_heads=8, key_dim=128)\n",
    "        self.dropout2 = layers.Dropout(0.3)\n",
    "        self.ffn2 = tf.keras.Sequential([\n",
    "            layers.Dense(128, activation='relu', kernel_initializer=\"he_normal\"),\n",
    "            layers.Dense(128, activation='relu', kernel_initializer=\"he_normal\"),\n",
    "        ])\n",
    "\n",
    "        self.layer_norm3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.attention3 = layers.MultiHeadAttention(num_heads=8, key_dim=128)\n",
    "        self.dropout3 = layers.Dropout(0.3)\n",
    "        self.ffn3 = tf.keras.Sequential([\n",
    "            layers.Dense(128, activation='relu', kernel_initializer=\"he_normal\"),\n",
    "            layers.Dense(128, activation='relu', kernel_initializer=\"he_normal\"),\n",
    "        ])\n",
    "\n",
    "        self.global_pool = layers.GlobalAveragePooling1D()\n",
    "        self.mlp = tf.keras.Sequential([\n",
    "            layers.Dense(256, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.4),\n",
    "            layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.4),\n",
    "            layers.Dense(16, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Project inputs to match the model dimension\n",
    "        x = self.projection(inputs)\n",
    "        x = self.layer_norm1(x)\n",
    "        attn_output = self.attention1(x, x)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        x = x + attn_output  # Residual connection\n",
    "\n",
    "        ffn_output = self.ffn1(x)\n",
    "        x = x + ffn_output  # Residual connection\n",
    "\n",
    "        # Second transformer block\n",
    "        x = self.layer_norm2(x)\n",
    "        attn_output = self.attention2(x, x)\n",
    "        attn_output = self.dropout2(attn_output)\n",
    "        x = x + attn_output\n",
    "\n",
    "        ffn_output = self.ffn2(x)\n",
    "        x = x + ffn_output\n",
    "\n",
    "        # Third transformer block\n",
    "        x = self.layer_norm3(x)\n",
    "        attn_output = self.attention3(x, x)\n",
    "        attn_output = self.dropout3(attn_output)\n",
    "        x = x + attn_output\n",
    "\n",
    "        ffn_output = self.ffn3(x)\n",
    "        x = x + ffn_output\n",
    "\n",
    "        # Global pooling and final MLP\n",
    "        x = self.global_pool(x)\n",
    "        return self.mlp(x)\n",
    "\n",
    "# Update the CombinedModel to reflect the change\n",
    "class CombinedModel(tf.keras.Model):\n",
    "    def __init__(self, team_input_shape, player_input_shape):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.team_model = TeamStatsModel(team_input_shape)\n",
    "        self.player_model = PlayerStatsModel(player_input_shape)\n",
    "        self.ball_model = BallToBallModel()\n",
    "        \n",
    "        self.final_mlp1 = layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "        self.dropout = layers.Dropout(0.3)\n",
    "        self.final_mlp2 = layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "        self.final_output = layers.Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        team_input, player_input, ball_input = inputs\n",
    "        team_output = self.team_model(team_input)        # Shape: (batch_size, 1, 16)\n",
    "        team_output = layers.Flatten()(team_output)      # Shape: (batch_size, 16)\n",
    "        player_output = self.player_model(player_input)  # Shape: (batch_size, 16)\n",
    "        ball_output = self.ball_model(ball_input)        # Shape: (batch_size, 16)\n",
    "        \n",
    "        # Concatenate along the last axis\n",
    "        combined = layers.concatenate([team_output, player_output, ball_output], axis=-1)\n",
    "        x = self.final_mlp1(combined)\n",
    "        x = self.dropout(x)\n",
    "        x = self.final_mlp2(x)\n",
    "        return self.final_output(x)\n",
    "\n",
    "# Import callbacks for learning rate scheduling and early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Check the shapes of inputs and labels\n",
    "team_input, player_input, ball_input = inputs\n",
    "print(f\"Shape of team_input: {team_input.shape}\")\n",
    "print(f\"Shape of player_input: {player_input.shape}\")\n",
    "print(f\"Shape of ball_input: {ball_input.shape}\")\n",
    "print(f\"Shape of labels: {labels.shape}\")\n",
    "\n",
    "# Ensure inputs and labels have the same number of samples\n",
    "min_samples = min(team_input.shape[0], player_input.shape[0], ball_input.shape[0], labels.shape[0])\n",
    "team_input = team_input[:min_samples]\n",
    "player_input = player_input[:min_samples]\n",
    "ball_input = ball_input[:min_samples]\n",
    "labels = labels[:min_samples]\n",
    "\n",
    "# Ensure inputs have the same shape\n",
    "team_input = tf.reshape(team_input, (min_samples, *team_input_shape))\n",
    "player_input = tf.reshape(player_input, (min_samples, *player_input_shape))\n",
    "ball_input = tf.reshape(ball_input, (min_samples, *inputs[2].shape[1:]))\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "(train_team_input, val_team_input, train_player_input, val_player_input, train_ball_input, val_ball_input, train_labels, val_labels) = train_test_split(\n",
    "    team_input.numpy(), player_input.numpy(), ball_input.numpy(), labels.numpy(), test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the split data back to tensors\n",
    "train_team_input = tf.convert_to_tensor(train_team_input)\n",
    "val_team_input = tf.convert_to_tensor(val_team_input)\n",
    "train_player_input = tf.convert_to_tensor(train_player_input)\n",
    "val_player_input = tf.convert_to_tensor(val_player_input)\n",
    "train_ball_input = tf.convert_to_tensor(train_ball_input)\n",
    "val_ball_input = tf.convert_to_tensor(val_ball_input)\n",
    "train_labels = tf.convert_to_tensor(train_labels)\n",
    "val_labels = tf.convert_to_tensor(val_labels)\n",
    "\n",
    "# Combine the inputs for training and validation\n",
    "train_inputs = [train_team_input, train_player_input, train_ball_input]\n",
    "val_inputs = [val_team_input, val_player_input, val_ball_input]\n",
    "\n",
    "# Instantiate and compile the model with a learning rate scheduler\n",
    "model = CombinedModel(team_input_shape, player_input_shape)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Define callbacks\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "\n",
    "# Add callbacks for early stopping and model checkpointing\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "# Train the model with updated callbacks\n",
    "history = model.fit(\n",
    "    train_inputs, train_labels,\n",
    "    epochs=200,\n",
    "    batch_size=16,\n",
    "    validation_data=(val_inputs, val_labels),\n",
    "    callbacks=[early_stopping, lr_scheduler, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_inputs, val_labels)\n",
    "print(f\"Validation Loss: {loss}, Validation Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5197404026985168, 0.533261239528656, 0.5895078182220459, 0.6084370017051697, 0.6170903444290161, 0.6354786157608032, 0.6517035961151123, 0.6598161458969116, 0.6830719113349915, 0.6760411262512207, 0.7014602422714233, 0.709031879901886, 0.7187669277191162, 0.7203894257545471, 0.739859402179718, 0.757706880569458, 0.7652785181999207, 0.7679827213287354, 0.7798810005187988, 0.7836668491363525, 0.7820443511009216, 0.8247701525688171, 0.8231476545333862, 0.8269335031509399, 0.8307192921638489, 0.846944272518158, 0.8426176309585571, 0.8528934717178345, 0.8550567626953125, 0.861005961894989, 0.863169252872467, 0.8653326034545898, 0.8664142489433289, 0.8739859461784363, 0.8858842849731445, 0.8869659304618835, 0.8929150700569153, 0.8918334245681763, 0.9021092653274536, 0.9004867672920227, 0.9053542613983154, 0.9091400504112244, 0.9107625484466553, 0.9118442535400391, 0.914548397064209, 0.915630042552948, 0.9177933931350708, 0.9199567437171936]\n",
      "[0.5053995847702026, 0.5507559180259705, 0.5572354197502136, 0.5485960841178894, 0.591792643070221, 0.5680345296859741, 0.5680345296859741, 0.5550755858421326, 0.591792643070221, 0.5896328091621399, 0.5982721447944641, 0.6220302581787109, 0.6069114208221436, 0.6069114208221436, 0.6133909225463867, 0.6047516465187073, 0.6263498663902283, 0.6025918126106262, 0.593952476978302, 0.6047516465187073, 0.6198704242706299, 0.6177105903625488, 0.6069114208221436, 0.6133909225463867, 0.6155507564544678, 0.6198704242706299, 0.6133909225463867, 0.6090712547302246, 0.6112310886383057, 0.6155507564544678, 0.6177105903625488, 0.6285097002983093, 0.6069114208221436, 0.6133909225463867, 0.6025918126106262, 0.6025918126106262, 0.6047516465187073, 0.6112310886383057, 0.6177105903625488, 0.6004319787025452, 0.6047516465187073, 0.6069114208221436, 0.6133909225463867, 0.6025918126106262, 0.6069114208221436, 0.6069114208221436, 0.6025918126106262, 0.6047516465187073]\n"
     ]
    }
   ],
   "source": [
    "# Print the history of accuracy\n",
    "print(history.history['accuracy'])\n",
    "print(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(val_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 23), dtype=float64, numpy=\n",
       " array([[  1.        ,   8.        ,   3.        ,   5.        ,\n",
       "           0.        ,   0.        ,   0.6       ,   8.        ,\n",
       "         258.        , 118.        ,  22.35      ,   8.85      ,\n",
       "           9.        ,   5.        ,   3.        ,   0.        ,\n",
       "           1.        ,   1.66666667,   9.        , 200.        ,\n",
       "         111.        ,  23.1       ,   8.51      ]])>,\n",
       " <tf.Tensor: shape=(22, 22), dtype=float64, numpy=\n",
       " array([[8.00000000e+00, 6.00000000e+00, 1.08000000e+02, 1.58820000e+02,\n",
       "         2.16000000e+01, 2.26200000e+01, 1.82000000e+02, 9.00000000e+00,\n",
       "         1.63500000e+02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 3.00000000e+00, 3.00000000e+00,\n",
       "         0.00000000e+00, 2.72727273e-01],\n",
       "        [8.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+02,\n",
       "         1.00000000e+00, 5.86000000e+00, 2.20000000e+01, 7.00000000e+00,\n",
       "         3.72700000e+01, 3.00000000e+01, 2.53000000e+02, 9.00000000e+00,\n",
       "         8.43000000e+00, 1.53400000e+02, 5.80000000e+01, 1.18100000e+03,\n",
       "         4.10000000e+01, 2.88048780e+01, 8.00000000e+00, 8.00000000e+00,\n",
       "         0.00000000e+00, 1.95121951e-01],\n",
       "        [8.00000000e+00, 8.00000000e+00, 1.90000000e+02, 1.35710000e+02,\n",
       "         2.37500000e+01, 2.95000000e+01, 1.08600000e+03, 4.40000000e+01,\n",
       "         1.24170000e+02, 1.00000000e+00, 1.40000000e+01, 0.00000000e+00,\n",
       "         1.40000000e+01, 4.40000000e+01, 1.50000000e+01, 3.48000000e+02,\n",
       "         2.30000000e+01, 1.51304348e+01, 2.00000000e+01, 2.00000000e+01,\n",
       "         0.00000000e+00, 4.34782609e-01],\n",
       "        [8.00000000e+00, 8.00000000e+00, 1.53000000e+02, 1.39090000e+02,\n",
       "         1.91200000e+01, 2.20400000e+01, 4.82000000e+02, 2.30000000e+01,\n",
       "         1.37620000e+02, 6.00000000e+00, 7.10000000e+01, 0.00000000e+00,\n",
       "         1.18300000e+01, 1.20000000e+01, 0.00000000e+00, 1.20000000e+02,\n",
       "         8.00000000e+00, 1.50000000e+01, 9.00000000e+00, 9.00000000e+00,\n",
       "         0.00000000e+00, 3.91304348e-01],\n",
       "        [7.00000000e+00, 7.00000000e+00, 2.47000000e+02, 1.68020000e+02,\n",
       "         3.52800000e+01, 2.42700000e+01, 9.71000000e+02, 4.00000000e+01,\n",
       "         1.16130000e+02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.60000000e+01, 1.40000000e+01,\n",
       "         2.00000000e+00, 3.90243902e-01],\n",
       "        [7.00000000e+00, 7.00000000e+00, 1.74000000e+02, 1.39200000e+02,\n",
       "         2.90000000e+01, 2.61100000e+01, 8.04000000e+02, 3.30000000e+01,\n",
       "         1.31780000e+02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.60000000e+01, 1.60000000e+01,\n",
       "         0.00000000e+00, 4.70588235e-01],\n",
       "        [3.00000000e+00, 2.00000000e+00, 4.60000000e+01, 1.12190000e+02,\n",
       "         2.30000000e+01, 2.30000000e+01, 4.60000000e+01, 2.00000000e+00,\n",
       "         1.12190000e+02, 5.00000000e+00, 6.00000000e+01, 1.00000000e+00,\n",
       "         1.20000000e+01, 5.00000000e+00, 1.00000000e+00, 6.00000000e+01,\n",
       "         2.00000000e+00, 3.00000000e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [8.00000000e+00, 8.00000000e+00, 8.80000000e+01, 1.33330000e+02,\n",
       "         1.10000000e+01, 2.57600000e+01, 1.48600000e+03, 6.70000000e+01,\n",
       "         1.24000000e+02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 4.50000000e+01, 4.00000000e+01,\n",
       "         5.00000000e+00, 6.33802817e-01],\n",
       "        [8.00000000e+00, 8.00000000e+00, 1.46000000e+02, 1.37730000e+02,\n",
       "         2.08500000e+01, 2.56500000e+01, 9.72000000e+02, 4.90000000e+01,\n",
       "         1.26490000e+02, 2.00000000e+00, 2.70000000e+01, 1.00000000e+00,\n",
       "         1.35000000e+01, 1.70000000e+01, 5.00000000e+00, 1.59000000e+02,\n",
       "         9.00000000e+00, 1.76666667e+01, 2.50000000e+01, 2.50000000e+01,\n",
       "         0.00000000e+00, 4.38596491e-01],\n",
       "        [7.00000000e+00, 5.00000000e+00, 8.40000000e+01, 1.29230000e+02,\n",
       "         1.68000000e+01, 1.76700000e+01, 3.98000000e+02, 3.50000000e+01,\n",
       "         9.37300000e+01, 2.52000000e+01, 1.96000000e+02, 8.00000000e+00,\n",
       "         7.73000000e+00, 1.75000000e+02, 5.30000000e+01, 1.46000000e+03,\n",
       "         4.80000000e+01, 3.04166667e+01, 2.30000000e+01, 2.30000000e+01,\n",
       "         0.00000000e+00, 4.79166667e-01],\n",
       "        [7.00000000e+00, 7.00000000e+00, 7.20000000e+01, 1.30900000e+02,\n",
       "         1.80000000e+01, 1.43000000e+01, 1.78000000e+02, 1.90000000e+01,\n",
       "         1.39050000e+02, 1.90000000e+01, 1.91000000e+02, 7.00000000e+00,\n",
       "         1.00500000e+01, 7.30000000e+01, 2.70000000e+01, 7.42000000e+02,\n",
       "         2.50000000e+01, 2.96800000e+01, 1.20000000e+01, 1.20000000e+01,\n",
       "         0.00000000e+00, 4.61538462e-01],\n",
       "        [7.00000000e+00, 4.00000000e+00, 3.20000000e+01, 1.33330000e+02,\n",
       "         1.60000000e+01, 1.25000000e+01, 4.30000000e+01, 6.00000000e+00,\n",
       "         9.28600000e+01, 2.60000000e+01, 1.82000000e+02, 1.70000000e+01,\n",
       "         7.00000000e+00, 4.60000000e+01, 2.20000000e+01, 3.60000000e+02,\n",
       "         1.20000000e+01, 3.00000000e+01, 2.00000000e+00, 2.00000000e+00,\n",
       "         0.00000000e+00, 1.66666667e-01],\n",
       "        [2.00000000e+00, 2.00000000e+00, 3.00000000e+00, 7.50000000e+01,\n",
       "         1.50000000e+00, 1.50000000e+00, 3.00000000e+00, 2.00000000e+00,\n",
       "         7.50000000e+01, 6.00000000e+00, 4.30000000e+01, 1.00000000e+00,\n",
       "         7.16000000e+00, 6.00000000e+00, 1.00000000e+00, 4.30000000e+01,\n",
       "         2.00000000e+00, 2.15000000e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [4.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 3.10000000e+00, 1.80000000e+01, 1.00000000e+01,\n",
       "         2.74600000e+01, 1.05000000e+01, 1.33000000e+02, 4.00000000e+00,\n",
       "         1.22700000e+01, 1.52200000e+02, 5.20000000e+01, 1.24400000e+03,\n",
       "         4.40000000e+01, 2.82727273e+01, 1.90000000e+01, 1.90000000e+01,\n",
       "         0.00000000e+00, 4.31818182e-01],\n",
       "        [8.00000000e+00, 8.00000000e+00, 2.10000000e+02, 1.46850000e+02,\n",
       "         2.62500000e+01, 3.95200000e+01, 2.89400000e+03, 9.90000000e+01,\n",
       "         1.35010000e+02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 5.60000000e+01, 5.60000000e+01,\n",
       "         0.00000000e+00, 5.65656566e-01],\n",
       "        [4.00000000e+00, 4.00000000e+00, 1.90000000e+01, 1.05550000e+02,\n",
       "         4.75000000e+00, 1.73700000e+01, 1.39000000e+02, 8.00000000e+00,\n",
       "         1.16220000e+02, 1.10000000e+01, 1.02000000e+02, 2.00000000e+00,\n",
       "         9.27000000e+00, 2.00000000e+01, 5.00000000e+00, 1.78000000e+02,\n",
       "         7.00000000e+00, 2.54285714e+01, 3.00000000e+00, 3.00000000e+00,\n",
       "         0.00000000e+00, 3.75000000e-01],\n",
       "        [8.00000000e+00, 8.00000000e+00, 2.05000000e+02, 1.07890000e+02,\n",
       "         2.92800000e+01, 3.50400000e+01, 3.12000000e+03, 1.03000000e+02,\n",
       "         1.42740000e+02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 2.00000000e+00, 0.00000000e+00, 2.70000000e+01,\n",
       "         2.00000000e+00, 1.35000000e+01, 5.00000000e+01, 5.00000000e+01,\n",
       "         0.00000000e+00, 4.90196078e-01],\n",
       "        [8.00000000e+00, 8.00000000e+00, 1.35000000e+02, 1.35000000e+02,\n",
       "         1.92800000e+01, 3.17800000e+01, 2.15900000e+03, 9.00000000e+01,\n",
       "         1.47280000e+02, 8.10000000e+00, 5.40000000e+01, 3.00000000e+00,\n",
       "         6.61000000e+00, 1.44100000e+02, 3.90000000e+01, 1.07600000e+03,\n",
       "         6.60000000e+01, 1.63030303e+01, 4.10000000e+01, 4.10000000e+01,\n",
       "         0.00000000e+00, 4.22680412e-01],\n",
       "        [9.00000000e+00, 7.00000000e+00, 1.01000000e+02, 1.21680000e+02,\n",
       "         2.52500000e+01, 3.43100000e+01, 1.01800000e+03, 5.70000000e+01,\n",
       "         1.25860000e+02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 5.30000000e+01, 4.70000000e+01,\n",
       "         6.00000000e+00, 7.06666667e-01],\n",
       "        [8.00000000e+00, 5.00000000e+00, 4.40000000e+01, 1.10000000e+02,\n",
       "         1.46600000e+01, 7.21000000e+00, 1.16000000e+02, 2.30000000e+01,\n",
       "         1.11660000e+02, 3.10000000e+01, 2.38000000e+02, 9.00000000e+00,\n",
       "         7.67000000e+00, 1.83000000e+02, 5.50000000e+01, 1.35000000e+03,\n",
       "         5.00000000e+01, 2.70000000e+01, 1.50000000e+01, 1.50000000e+01,\n",
       "         0.00000000e+00, 3.00000000e-01],\n",
       "        [7.00000000e+00, 2.00000000e+00, 1.00000000e+01, 9.09000000e+01,\n",
       "         1.00000000e+01, 9.26000000e+00, 9.40000000e+01, 1.90000000e+01,\n",
       "         6.44200000e+01, 2.60000000e+01, 2.15000000e+02, 1.00000000e+01,\n",
       "         8.26000000e+00, 2.18600000e+02, 7.30000000e+01, 1.67300000e+03,\n",
       "         5.80000000e+01, 2.88448276e+01, 1.50000000e+01, 1.50000000e+01,\n",
       "         0.00000000e+00, 2.58620690e-01],\n",
       "        [7.00000000e+00, 2.00000000e+00, 1.00000000e+00, 3.33300000e+01,\n",
       "         1.00000000e+00, 3.75000000e+00, 4.80000000e+01, 1.60000000e+01,\n",
       "         5.15900000e+01, 2.50000000e+01, 1.78000000e+02, 8.00000000e+00,\n",
       "         7.12000000e+00, 2.56100000e+02, 8.20000000e+01, 1.78100000e+03,\n",
       "         7.10000000e+01, 2.50845070e+01, 1.00000000e+01, 1.00000000e+01,\n",
       "         0.00000000e+00, 1.40845070e-01]])>,\n",
       " <tf.Tensor: shape=(271, 4), dtype=float32, numpy=\n",
       " array([[1. , 0.1, 0. , 0. ],\n",
       "        [1. , 0.2, 4. , 0. ],\n",
       "        [1. , 0.3, 5. , 0. ],\n",
       "        ...,\n",
       "        [0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(), dtype=float64, numpy=0.0>,\n",
       " array([1.1613842e-07], dtype=float32))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_inputs[0][0], val_inputs[1][0], val_inputs[2][0], val_labels[0], pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 200, 4), dtype=float32, numpy=\n",
       "array([[[1.00e+00, 1.00e-01, 0.00e+00, 0.00e+00],\n",
       "        [1.00e+00, 2.00e-01, 4.00e+00, 0.00e+00],\n",
       "        [1.00e+00, 3.00e-01, 5.00e+00, 0.00e+00],\n",
       "        [1.00e+00, 4.00e-01, 7.00e+00, 0.00e+00],\n",
       "        [1.00e+00, 5.00e-01, 1.00e+01, 0.00e+00],\n",
       "        [1.00e+00, 6.00e-01, 1.20e+01, 0.00e+00],\n",
       "        [1.00e+00, 7.00e-01, 1.60e+01, 0.00e+00],\n",
       "        [1.00e+00, 8.00e-01, 1.60e+01, 0.00e+00],\n",
       "        [1.00e+00, 1.10e+00, 1.60e+01, 1.00e+00],\n",
       "        [1.00e+00, 1.20e+00, 1.70e+01, 1.00e+00],\n",
       "        [1.00e+00, 1.30e+00, 1.70e+01, 1.00e+00],\n",
       "        [1.00e+00, 1.40e+00, 2.10e+01, 1.00e+00],\n",
       "        [1.00e+00, 1.50e+00, 2.50e+01, 1.00e+00],\n",
       "        [1.00e+00, 1.60e+00, 2.60e+01, 1.00e+00],\n",
       "        [1.00e+00, 2.10e+00, 2.60e+01, 1.00e+00],\n",
       "        [1.00e+00, 2.20e+00, 2.60e+01, 1.00e+00],\n",
       "        [1.00e+00, 2.30e+00, 2.70e+01, 1.00e+00],\n",
       "        [1.00e+00, 2.40e+00, 2.70e+01, 1.00e+00],\n",
       "        [1.00e+00, 2.50e+00, 2.70e+01, 1.00e+00],\n",
       "        [1.00e+00, 2.60e+00, 3.10e+01, 1.00e+00],\n",
       "        [1.00e+00, 3.10e+00, 3.10e+01, 1.00e+00],\n",
       "        [1.00e+00, 3.20e+00, 3.30e+01, 1.00e+00],\n",
       "        [1.00e+00, 3.30e+00, 3.50e+01, 1.00e+00],\n",
       "        [1.00e+00, 3.40e+00, 3.50e+01, 1.00e+00],\n",
       "        [1.00e+00, 3.50e+00, 4.10e+01, 1.00e+00],\n",
       "        [1.00e+00, 3.60e+00, 4.10e+01, 1.00e+00],\n",
       "        [1.00e+00, 3.70e+00, 4.20e+01, 1.00e+00],\n",
       "        [1.00e+00, 3.80e+00, 4.20e+01, 1.00e+00],\n",
       "        [1.00e+00, 4.10e+00, 4.30e+01, 1.00e+00],\n",
       "        [1.00e+00, 4.20e+00, 4.90e+01, 1.00e+00],\n",
       "        [1.00e+00, 4.30e+00, 4.90e+01, 1.00e+00],\n",
       "        [1.00e+00, 4.40e+00, 5.00e+01, 1.00e+00],\n",
       "        [1.00e+00, 4.50e+00, 5.00e+01, 1.00e+00],\n",
       "        [1.00e+00, 4.60e+00, 5.10e+01, 1.00e+00],\n",
       "        [1.00e+00, 5.10e+00, 5.20e+01, 1.00e+00],\n",
       "        [1.00e+00, 5.20e+00, 5.20e+01, 2.00e+00],\n",
       "        [1.00e+00, 5.30e+00, 5.30e+01, 2.00e+00],\n",
       "        [1.00e+00, 5.40e+00, 5.70e+01, 2.00e+00],\n",
       "        [1.00e+00, 5.50e+00, 5.70e+01, 2.00e+00],\n",
       "        [1.00e+00, 5.60e+00, 5.70e+01, 2.00e+00],\n",
       "        [1.00e+00, 6.10e+00, 5.80e+01, 2.00e+00],\n",
       "        [1.00e+00, 6.20e+00, 5.80e+01, 2.00e+00],\n",
       "        [1.00e+00, 6.30e+00, 5.90e+01, 2.00e+00],\n",
       "        [1.00e+00, 6.40e+00, 6.00e+01, 2.00e+00],\n",
       "        [1.00e+00, 6.50e+00, 6.00e+01, 2.00e+00],\n",
       "        [1.00e+00, 6.60e+00, 6.00e+01, 2.00e+00],\n",
       "        [1.00e+00, 7.10e+00, 6.10e+01, 2.00e+00],\n",
       "        [1.00e+00, 7.20e+00, 6.10e+01, 2.00e+00],\n",
       "        [1.00e+00, 7.30e+00, 6.20e+01, 2.00e+00],\n",
       "        [1.00e+00, 7.40e+00, 6.20e+01, 2.00e+00],\n",
       "        [1.00e+00, 7.50e+00, 6.40e+01, 2.00e+00],\n",
       "        [1.00e+00, 7.60e+00, 6.50e+01, 2.00e+00],\n",
       "        [1.00e+00, 7.70e+00, 6.60e+01, 2.00e+00],\n",
       "        [1.00e+00, 8.10e+00, 6.70e+01, 2.00e+00],\n",
       "        [1.00e+00, 8.20e+00, 6.80e+01, 2.00e+00],\n",
       "        [1.00e+00, 8.30e+00, 6.80e+01, 2.00e+00],\n",
       "        [1.00e+00, 8.40e+00, 6.90e+01, 2.00e+00],\n",
       "        [1.00e+00, 8.50e+00, 7.00e+01, 2.00e+00],\n",
       "        [1.00e+00, 8.60e+00, 7.10e+01, 2.00e+00],\n",
       "        [1.00e+00, 9.10e+00, 7.10e+01, 3.00e+00],\n",
       "        [1.00e+00, 9.20e+00, 7.10e+01, 3.00e+00],\n",
       "        [1.00e+00, 9.30e+00, 7.20e+01, 3.00e+00],\n",
       "        [1.00e+00, 9.40e+00, 7.20e+01, 3.00e+00],\n",
       "        [1.00e+00, 9.50e+00, 7.30e+01, 3.00e+00],\n",
       "        [1.00e+00, 9.60e+00, 7.30e+01, 3.00e+00],\n",
       "        [1.00e+00, 1.01e+01, 7.40e+01, 3.00e+00],\n",
       "        [1.00e+00, 1.02e+01, 7.60e+01, 3.00e+00],\n",
       "        [1.00e+00, 1.03e+01, 7.70e+01, 3.00e+00],\n",
       "        [1.00e+00, 1.04e+01, 7.90e+01, 3.00e+00],\n",
       "        [1.00e+00, 1.05e+01, 8.10e+01, 3.00e+00],\n",
       "        [1.00e+00, 1.06e+01, 8.20e+01, 3.00e+00],\n",
       "        [1.00e+00, 1.07e+01, 8.20e+01, 4.00e+00],\n",
       "        [1.00e+00, 1.08e+01, 8.20e+01, 4.00e+00],\n",
       "        [1.00e+00, 1.11e+01, 8.20e+01, 4.00e+00],\n",
       "        [1.00e+00, 1.12e+01, 8.40e+01, 4.00e+00],\n",
       "        [1.00e+00, 1.13e+01, 8.50e+01, 4.00e+00],\n",
       "        [1.00e+00, 1.14e+01, 8.50e+01, 4.00e+00],\n",
       "        [1.00e+00, 1.15e+01, 8.60e+01, 4.00e+00],\n",
       "        [1.00e+00, 1.16e+01, 8.70e+01, 4.00e+00],\n",
       "        [1.00e+00, 1.21e+01, 8.80e+01, 4.00e+00],\n",
       "        [1.00e+00, 1.22e+01, 8.90e+01, 4.00e+00],\n",
       "        [1.00e+00, 1.23e+01, 9.00e+01, 4.00e+00],\n",
       "        [1.00e+00, 1.24e+01, 9.20e+01, 4.00e+00],\n",
       "        [1.00e+00, 1.25e+01, 9.20e+01, 4.00e+00],\n",
       "        [1.00e+00, 1.26e+01, 9.30e+01, 4.00e+00],\n",
       "        [1.00e+00, 1.31e+01, 9.40e+01, 4.00e+00],\n",
       "        [1.00e+00, 1.32e+01, 9.40e+01, 4.00e+00],\n",
       "        [1.00e+00, 1.33e+01, 9.40e+01, 4.00e+00],\n",
       "        [1.00e+00, 1.34e+01, 9.50e+01, 4.00e+00],\n",
       "        [1.00e+00, 1.35e+01, 9.50e+01, 4.00e+00],\n",
       "        [1.00e+00, 1.36e+01, 9.50e+01, 4.00e+00],\n",
       "        [1.00e+00, 1.41e+01, 9.50e+01, 5.00e+00],\n",
       "        [1.00e+00, 1.42e+01, 9.50e+01, 5.00e+00],\n",
       "        [1.00e+00, 1.43e+01, 9.50e+01, 5.00e+00],\n",
       "        [1.00e+00, 1.44e+01, 1.01e+02, 5.00e+00],\n",
       "        [1.00e+00, 1.45e+01, 1.01e+02, 5.00e+00],\n",
       "        [1.00e+00, 1.46e+01, 1.02e+02, 5.00e+00],\n",
       "        [1.00e+00, 1.51e+01, 1.08e+02, 5.00e+00],\n",
       "        [1.00e+00, 1.52e+01, 1.08e+02, 6.00e+00],\n",
       "        [1.00e+00, 1.53e+01, 1.09e+02, 6.00e+00],\n",
       "        [1.00e+00, 1.54e+01, 1.10e+02, 6.00e+00],\n",
       "        [1.00e+00, 1.55e+01, 1.12e+02, 6.00e+00],\n",
       "        [1.00e+00, 1.56e+01, 1.13e+02, 6.00e+00],\n",
       "        [1.00e+00, 1.57e+01, 1.13e+02, 6.00e+00],\n",
       "        [1.00e+00, 1.61e+01, 1.14e+02, 6.00e+00],\n",
       "        [1.00e+00, 1.62e+01, 1.14e+02, 7.00e+00],\n",
       "        [1.00e+00, 1.63e+01, 1.18e+02, 7.00e+00],\n",
       "        [1.00e+00, 1.64e+01, 1.18e+02, 7.00e+00],\n",
       "        [1.00e+00, 1.65e+01, 1.20e+02, 7.00e+00],\n",
       "        [1.00e+00, 1.66e+01, 1.20e+02, 7.00e+00],\n",
       "        [1.00e+00, 1.71e+01, 1.26e+02, 7.00e+00],\n",
       "        [1.00e+00, 1.72e+01, 1.27e+02, 7.00e+00],\n",
       "        [1.00e+00, 1.73e+01, 1.31e+02, 7.00e+00],\n",
       "        [1.00e+00, 1.74e+01, 1.32e+02, 7.00e+00],\n",
       "        [1.00e+00, 1.75e+01, 1.34e+02, 7.00e+00],\n",
       "        [1.00e+00, 1.76e+01, 1.34e+02, 7.00e+00],\n",
       "        [1.00e+00, 1.77e+01, 1.34e+02, 8.00e+00],\n",
       "        [1.00e+00, 1.81e+01, 1.40e+02, 8.00e+00],\n",
       "        [1.00e+00, 1.82e+01, 1.40e+02, 8.00e+00],\n",
       "        [1.00e+00, 1.83e+01, 1.44e+02, 8.00e+00],\n",
       "        [1.00e+00, 1.84e+01, 1.46e+02, 8.00e+00],\n",
       "        [1.00e+00, 1.85e+01, 1.48e+02, 8.00e+00],\n",
       "        [1.00e+00, 1.86e+01, 1.52e+02, 8.00e+00],\n",
       "        [1.00e+00, 1.87e+01, 1.53e+02, 8.00e+00],\n",
       "        [1.00e+00, 1.91e+01, 1.55e+02, 8.00e+00],\n",
       "        [1.00e+00, 1.92e+01, 1.57e+02, 8.00e+00],\n",
       "        [1.00e+00, 1.93e+01, 1.58e+02, 8.00e+00],\n",
       "        [1.00e+00, 1.94e+01, 1.59e+02, 8.00e+00],\n",
       "        [1.00e+00, 1.95e+01, 1.59e+02, 8.00e+00],\n",
       "        [1.00e+00, 1.96e+01, 1.59e+02, 8.00e+00],\n",
       "        [1.00e+00, 1.97e+01, 1.60e+02, 8.00e+00],\n",
       "        [1.00e+00, 1.98e+01, 1.60e+02, 9.00e+00],\n",
       "        [2.00e+00, 1.00e-01, 1.00e+00, 0.00e+00],\n",
       "        [2.00e+00, 2.00e-01, 1.00e+00, 0.00e+00],\n",
       "        [2.00e+00, 3.00e-01, 2.00e+00, 0.00e+00],\n",
       "        [2.00e+00, 4.00e-01, 6.00e+00, 0.00e+00],\n",
       "        [2.00e+00, 5.00e-01, 1.00e+01, 0.00e+00],\n",
       "        [2.00e+00, 6.00e-01, 1.10e+01, 0.00e+00],\n",
       "        [2.00e+00, 1.10e+00, 1.50e+01, 0.00e+00],\n",
       "        [2.00e+00, 1.20e+00, 1.50e+01, 1.00e+00],\n",
       "        [2.00e+00, 1.30e+00, 1.70e+01, 1.00e+00],\n",
       "        [2.00e+00, 1.40e+00, 1.90e+01, 1.00e+00],\n",
       "        [2.00e+00, 1.50e+00, 2.10e+01, 1.00e+00],\n",
       "        [2.00e+00, 1.60e+00, 2.20e+01, 1.00e+00],\n",
       "        [2.00e+00, 1.70e+00, 2.30e+01, 1.00e+00],\n",
       "        [2.00e+00, 1.80e+00, 2.30e+01, 2.00e+00],\n",
       "        [2.00e+00, 2.10e+00, 2.50e+01, 2.00e+00],\n",
       "        [2.00e+00, 2.20e+00, 2.50e+01, 2.00e+00],\n",
       "        [2.00e+00, 2.30e+00, 2.50e+01, 2.00e+00],\n",
       "        [2.00e+00, 2.40e+00, 2.50e+01, 2.00e+00],\n",
       "        [2.00e+00, 2.50e+00, 2.60e+01, 2.00e+00],\n",
       "        [2.00e+00, 2.60e+00, 3.00e+01, 2.00e+00],\n",
       "        [2.00e+00, 3.10e+00, 3.00e+01, 2.00e+00],\n",
       "        [2.00e+00, 3.20e+00, 3.40e+01, 2.00e+00],\n",
       "        [2.00e+00, 3.30e+00, 3.60e+01, 2.00e+00],\n",
       "        [2.00e+00, 3.40e+00, 3.80e+01, 2.00e+00],\n",
       "        [2.00e+00, 3.50e+00, 3.90e+01, 2.00e+00],\n",
       "        [2.00e+00, 3.60e+00, 4.00e+01, 2.00e+00],\n",
       "        [2.00e+00, 4.10e+00, 4.60e+01, 2.00e+00],\n",
       "        [2.00e+00, 4.20e+00, 4.70e+01, 2.00e+00],\n",
       "        [2.00e+00, 4.30e+00, 5.10e+01, 2.00e+00],\n",
       "        [2.00e+00, 4.40e+00, 5.10e+01, 2.00e+00],\n",
       "        [2.00e+00, 4.50e+00, 5.20e+01, 2.00e+00],\n",
       "        [2.00e+00, 4.60e+00, 5.60e+01, 2.00e+00],\n",
       "        [2.00e+00, 5.10e+00, 5.80e+01, 2.00e+00],\n",
       "        [2.00e+00, 5.20e+00, 5.80e+01, 2.00e+00],\n",
       "        [2.00e+00, 5.30e+00, 6.00e+01, 2.00e+00],\n",
       "        [2.00e+00, 5.40e+00, 6.10e+01, 2.00e+00],\n",
       "        [2.00e+00, 5.50e+00, 6.10e+01, 3.00e+00],\n",
       "        [2.00e+00, 5.60e+00, 6.10e+01, 3.00e+00],\n",
       "        [2.00e+00, 6.10e+00, 6.10e+01, 3.00e+00],\n",
       "        [2.00e+00, 6.20e+00, 6.20e+01, 3.00e+00],\n",
       "        [2.00e+00, 6.30e+00, 6.20e+01, 3.00e+00],\n",
       "        [2.00e+00, 6.40e+00, 6.20e+01, 4.00e+00],\n",
       "        [2.00e+00, 6.50e+00, 6.20e+01, 4.00e+00],\n",
       "        [2.00e+00, 6.60e+00, 6.20e+01, 4.00e+00],\n",
       "        [2.00e+00, 7.10e+00, 6.20e+01, 4.00e+00],\n",
       "        [2.00e+00, 7.20e+00, 6.20e+01, 4.00e+00],\n",
       "        [2.00e+00, 7.30e+00, 6.30e+01, 4.00e+00],\n",
       "        [2.00e+00, 7.40e+00, 6.30e+01, 4.00e+00],\n",
       "        [2.00e+00, 7.50e+00, 6.30e+01, 5.00e+00],\n",
       "        [2.00e+00, 7.60e+00, 6.30e+01, 5.00e+00],\n",
       "        [2.00e+00, 8.10e+00, 6.40e+01, 5.00e+00],\n",
       "        [2.00e+00, 8.20e+00, 6.50e+01, 5.00e+00],\n",
       "        [2.00e+00, 8.30e+00, 6.50e+01, 5.00e+00],\n",
       "        [2.00e+00, 8.40e+00, 6.60e+01, 5.00e+00],\n",
       "        [2.00e+00, 8.50e+00, 6.70e+01, 5.00e+00],\n",
       "        [2.00e+00, 8.60e+00, 6.70e+01, 5.00e+00],\n",
       "        [2.00e+00, 9.10e+00, 6.70e+01, 5.00e+00],\n",
       "        [2.00e+00, 9.20e+00, 7.10e+01, 5.00e+00],\n",
       "        [2.00e+00, 9.30e+00, 7.10e+01, 5.00e+00],\n",
       "        [2.00e+00, 9.40e+00, 7.20e+01, 5.00e+00],\n",
       "        [2.00e+00, 9.50e+00, 7.30e+01, 5.00e+00],\n",
       "        [2.00e+00, 9.60e+00, 7.30e+01, 5.00e+00],\n",
       "        [2.00e+00, 1.01e+01, 7.40e+01, 5.00e+00],\n",
       "        [2.00e+00, 1.02e+01, 7.50e+01, 5.00e+00],\n",
       "        [2.00e+00, 1.03e+01, 7.90e+01, 5.00e+00],\n",
       "        [2.00e+00, 1.04e+01, 7.90e+01, 5.00e+00],\n",
       "        [2.00e+00, 1.05e+01, 8.00e+01, 5.00e+00],\n",
       "        [2.00e+00, 1.06e+01, 8.00e+01, 5.00e+00]]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(val_inputs[2][0:1][0, :200], (1, 200, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 05:36:28.181817: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_36', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 05:36:36.934227: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_24', 128 bytes spill stores, 128 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.4254458e-07]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([val_inputs[0][0:1], val_inputs[1][0:1], tf.reshape(val_inputs[2][0:1][0, :200], (1, 200, 4))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
